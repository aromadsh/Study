{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax 와 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        \n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        self.x = None\n",
    "\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    if exp_x.ndim == 1:\n",
    "        sum_exp_x = np.sum(exp_x)\n",
    "    else:\n",
    "        sum_exp_x = np.sum(exp_x, axis=1).reshape(-1, 1)\n",
    "    y = exp_x/sum_exp_x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient_no_batch(f, x):\n",
    "    h = 1e-7\n",
    "\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "\n",
    "        #f(x + h)\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        #f(x - h)\n",
    "        x[idx] = float(tmp_val) - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_no_batch(f, X)\n",
    "\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    \n",
    "    delta = 1e-7\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + delta))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size:\n",
    "            dx = (self.y - self.t)/batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx/batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # x = self.layers['Affine1'].forward(x)\n",
    "        # x = self.layers['Relu1'].forward(x)\n",
    "        # x = self.layers['Affine2'].forward(x)\n",
    "\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = self.lastLayer.forward(y, t)\n",
    "        return loss\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t)/float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    def _change_one_hot_label(X):\n",
    "        T = np.zeros((X.size, 10))\n",
    "        for idx, row in enumerate(T):\n",
    "            row[X[idx]] = 1\n",
    "\n",
    "        return T\n",
    "\n",
    "    with open('mnist.pkl', 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "        \n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "            \n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
    "    \n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100  # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train acc, test acc | 0.1048, 0.1024\n",
      "600 train acc, test acc | 0.9002166666666667, 0.905\n",
      "1200 train acc, test acc | 0.9229, 0.9241\n",
      "1800 train acc, test acc | 0.9341166666666667, 0.9345\n",
      "2400 train acc, test acc | 0.9456833333333333, 0.9437\n",
      "3000 train acc, test acc | 0.9514333333333334, 0.9492\n",
      "3600 train acc, test acc | 0.958, 0.9548\n",
      "4200 train acc, test acc | 0.9626833333333333, 0.9582\n",
      "4800 train acc, test acc | 0.9656, 0.9611\n",
      "5400 train acc, test acc | 0.9683833333333334, 0.9618\n",
      "6000 train acc, test acc | 0.97075, 0.9645\n",
      "6600 train acc, test acc | 0.9713333333333334, 0.9643\n",
      "7200 train acc, test acc | 0.97405, 0.9671\n",
      "7800 train acc, test acc | 0.9748833333333333, 0.9675\n",
      "8400 train acc, test acc | 0.97655, 0.9679\n",
      "9000 train acc, test acc | 0.979, 0.9702\n",
      "9600 train acc, test acc | 0.98015, 0.9706\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in (\"W1\", \"b1\", \"W2\", \"b2\"):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(f\"{i} train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label=\"train acc\")\n",
    "plt.plot(x, test_acc_list, label=\"test acc\", linestyle=\"--\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
